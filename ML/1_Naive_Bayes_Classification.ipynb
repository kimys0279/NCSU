{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. Naive Bayes Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+6x9hbgrDPfnMh7IXpmSS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimys0279/NCSU/blob/main/ML/1_Naive_Bayes_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKIPn7oOt3cQ"
      },
      "source": [
        "나이브 베이즈는 스팸 메일 필터, 텍스트 분류, 감정 분석, 추천 시스템 등에 광범위하게 활용되는 분류 기법입니다. 나이브 베이즈 분류에 대해서 배우기 위해서는 베이즈 정리를 먼저 알아야 합니다. 베이즈 정리를 모르신다면 DATA - 10. 베이즈 추정(Bayesian Estimation)을 먼저 보고 오시기 바랍니다.\r\n",
        "\r\n",
        "머신러닝을 통해 어떤 동물의 사진이 있을 때 그 동물이 호랑이인지 고양이인지 얼룩말인지 등을 구분할 수 있습니다. 사전에 수많은 호랑이, 고양이, 얼룩말 사진에 대해 학습을 시킵니다. 다양한 자세, 표정, 생김새, 털의 색깔 등을 가진 호랑이, 고양이, 얼룩말에 대해 '이 사진은 호랑이고, 이 사진은 고양이야'라고 학습시키는 것입니다. 학습된 머신러닝 모델은 이제 호랑이, 고양이, 얼룩말을 정확히 분류할 수 있습니다. 이제는 학습시 사용되었던 사진이 아닌 새로운 사진을 갖다 줬을 때도 정확히 분류할 수 있습니다. 이렇게 사전 데이터를 기반으로 충분히 학습시키는 방법을 지도학습(Supervised learning)이라고 합니다. \r\n",
        "\r\n",
        "지도학습을 하기 위한 첫 스텝은 Feature와 Label을 파악하는 것입니다. Label은 우리가 원하는 분류 결과입니다. 위 예시에서는 호랑이, 고양이, 얼룩말이 Label입니다. 이 Label 결과에 영항을 주는 요소를 Feature라고 합니다. 동물의 자세, 표정, 생김새, 털의 색깔 등이 바로 Feature입니다. 즉 수많은 동물의 자세, 표정, 생김새, 털의 색깔(Feature)을 기반으로 그 동물이 호랑이인지 고양이인지 얼룩말인지(Label) 분류를 하는 것입니다.\r\n",
        "\r\n",
        "나이브 베이즈 분류는 지도학습의 일종입니다. 따라서 Feature와 Label이 필요합니다. Feature에 따라 Label을 분류하는데 베이즈 정리를 사용하는 것이 특징입니다. 또한 모든 Feature가 서로 독립(independent)이어야 한다는 가정이 필요합니다.\r\n",
        "\r\n",
        "아래의 컨텐츠는 Udacity와 DataCamp의 내용을 Mix해서 정리해놓은 것입니다. (Reference1)\r\n",
        "\r\n",
        "Classification Workflow\r\n",
        "분류를 하기 위한 첫 스텝은 Feature와 Label을 파악하는 것이라고 했습니다. Label은 우리가 원하는 분류 결과입니다. 스팸 메일을 예로 들면 스팸 메일인지 아닌지의 여부가 Label입니다. 이 Label 결과에 영항을 주는 요소가 Feature입니다. 역시 스팸 메일을 예로 들면, 스팸 메일의 제목 및 내용에 기재된 광고성 단어, 비속어, 성적 용어 등입니다. \r\n",
        "\r\n",
        "Feature -> 광고성 단어 개수, 비속어 개수, 성적 용어 개수 등... (각각이 하나의 Feature이며, 하나의 분류 모델에는 여러 개의 Feature가 있음)\r\n",
        "\r\n",
        "Label -> 스팸 메일인 경우 Label = 1, 스팸 메일이 아닌 경우 Label = 0\r\n",
        "\r\n",
        "분류는 두 단계로 나누어집니다. 훈련 단계와 테스트 단계입니다. 훈련 단계에서는 주어진 Training data set을 통해 classifier 모델을 훈련시키고, 테스트 단계에서는 classfier 모델의 성능(performance)을 평가합니다. 성능(performance)은 정밀도(accuracy),  정확성(Precision), 재현율(Recall) 등으로 측정할 수 있습니다. (정밀도, 정확성, 재현율이란 무엇인가? Reference 2) \r\n",
        "\r\n",
        "\r\n",
        "출처: DataCamp\r\n",
        "나이브 베이즈 분류기(Naive Bayes Classifier)란 무엇인가?\r\n",
        "위에서 설명했듯이 나이브 베이즈 분류는 베이즈 정리에 기반한 통계적 분류 기법입니다. 가장 단순한 지도 학습 (supervised learning) 중 하나입니다. 나이브 베이즈 분류기는 빠르고, 정확하며, 믿을만한 알고리즘입니다. 정확성도 높고 대용량 데이터에 대해 속도도 빠릅니다.\r\n",
        "\r\n",
        "나이브 베이즈는 feature끼리 서로 독립이라는 조건이 필요합니다. 즉, 스펨 메일 분류에서 광고성 단어의 개수와 비속어의 개수가 서로 연관이 있어서는 안 됩니다. \r\n",
        "\r\n",
        "나이브 베이즈는 어떻게 동작하는가?\r\n",
        "예를 들어 설명하겠습니다. 날씨 정보와 축구 경기 여부에 대한 데이터가 있습니다. 날씨에 대한 정보를 기반으로 축구를 할것인지 안 할 것인지 확률을 구하는 예제입니다.\r\n",
        "\r\n",
        "\r\n",
        "출처: DataCamp\r\n",
        "먼저, 맨 왼쪽 테이블을 보겠습니다. 날씨에 따라 축구를 했는지 안했는지에 대한 과거 데이터입니다. 이 과거 데이터를 먼저 Training 시켜 모델을 만든 뒤 그 모델을 기반으로 어떤 날씨가 주어졌을 때 축구를 할지 안 할지 판단하는 것이 목적입니다.\r\n",
        "\r\n",
        "Frequency Table은 주어진 과거 데이터를 횟수로 표현한 것입니다. Likelihood Table 1은 각 Feature (여기서는 날씨)에 대한 확률, 각 Label (여기서는 축구를 할지 말지 여부)에 대한 확률을 구한 것입니다. Likelihood Table 2는 각 Feature에 대한 사후 확률을 구한 것입니다.\r\n",
        "\r\n",
        "Feature가 하나일 때 나이브 베이즈 분류\r\n",
        "문제 1. 날씨가 overcast일 때 경기를 할 확률은?\r\n",
        "P(Yes|Overcast) = P(Overcast|Yes) P(Yes) / P(Overcast)   <- 베이즈 정리에 의해\r\n",
        "\r\n",
        "1. 사전 확률\r\n",
        "\r\n",
        "P(Overcast) = 4/14 = 0.29\r\n",
        "\r\n",
        "P(Yes) = 9/14 = 0.64\r\n",
        "\r\n",
        "2. 사후 확률\r\n",
        "\r\n",
        "P(Overcast|Yes) = 4/9 = 0.44\r\n",
        "\r\n",
        "3. 베이즈 정리 공식에 대입\r\n",
        "\r\n",
        "P(Yes|Overcast) = P(Overcast|Yes) P(Yes) / P(Overcast) = 0.44 * 0.64 / 0.29 = 0.98\r\n",
        "\r\n",
        "즉, 날씨가 Overcast일 때 축구를 할 확률이 0.98이라는 뜻입니다.\r\n",
        "\r\n",
        "문제 2. 날씨가 Overcast일 때 경기를 하지 않을 확률은?\r\n",
        "P(No|Overcast) = P(Overcast|No) P(No) / P(Overcast)\r\n",
        "\r\n",
        "1. 사전 확률\r\n",
        "\r\n",
        "P(Overcast) = 4/14 = 0.29\r\n",
        "\r\n",
        "P(No) = 5/14 = 0.36\r\n",
        "\r\n",
        "2. 사후 확률\r\n",
        "\r\n",
        "P(Overcast|No) = 0/9 = 0\r\n",
        "\r\n",
        "3. 베이즈 정리 공식에 대입\r\n",
        "\r\n",
        "P(No|Overcast) = P(Overcast|No) P(No) / P(Overcast) = 0 * 0.36 / 0.29 = 0\r\n",
        "\r\n",
        "즉, 날씨가 Overcast일 때 축구를 할 확률이 0이라는 뜻입니다.\r\n",
        "\r\n",
        "P(Yes|Overcast) = 0.98, P(No|Overcast) = 0입니다. 즉, 날씨가 Overcast일 때 축구를 하는 확률은 0.98, 축구를 하지 않을 확률은 0입니다. 두 확률을 비교한 뒤 더 높은 확률의 Label로 분류를 하면 됩니다. 두 확률을 비교했을 때 'Yes' Label의 확률이 0.98로 더 높습니다. 따라서 나이브 베이즈 분류기는 날씨가 Overcast일 때 축구를 할 것이라고 판단합니다.\r\n",
        "\r\n",
        "Feature가 Multiple일 때 나이브 베이즈 분류\r\n",
        " \r\n",
        "\r\n",
        "\r\n",
        "출처: DataCamp\r\n",
        "문제 1. 날씨가 overcast, 기온이 Mild일 때 경기를 할 확률은?\r\n",
        "P(Paly=Yes | Weather=Overcast, Temp=Mild) = P(Weather=Overcast, Temp=Mild | Play=Yes) P(Play=Yes) / P(Weather=Overcast, Temp=Mild)\r\n",
        "\r\n",
        "P(Weather=Overcast, Temp=Mild | Play=Yes) = P(Overcast|Yes) P(Mild|Yes)\r\n",
        "\r\n",
        "P(Weather=Overcast, Temp=Mild) = P(Weather=Overcast) P(Temp=Mild) = (4/14) * (6/14) = 0.1224\r\n",
        "\r\n",
        "1. 사전 확률\r\n",
        "\r\n",
        "P(Yes) = 9/14 = 0.64\r\n",
        "\r\n",
        "2. 사후 확률\r\n",
        "\r\n",
        "P(Overcast|Yes) = 4/9 = 0.44\r\n",
        "\r\n",
        "P(Mild|Yes) = 4/9 = 0.44\r\n",
        "\r\n",
        "3. 베이즈 공식에 대입\r\n",
        "\r\n",
        "P(Weather=Overcast, Temp=Mild | Play=Yes) = P(Overcast|Yes) P(Mild|Yes) = 0.44 * 0.44 = 0.1936\r\n",
        "\r\n",
        "P(Paly=Yes | Weather=Overcast, Temp=Mild) = P(Weather=Overcast, Temp=Mild | Play=Yes) P(Play=Yes) / P(Weather=Overcast, Temp=Mild)\r\n",
        "\r\n",
        "= 0.1936 * 0.64 / 0.1224 = 1\r\n",
        "\r\n",
        "문제 2. 날씨가 overcast, 기온이 Mild일 때 경기를 하지 않을 확률은?\r\n",
        "P(Paly=No | Weather=Overcast, Temp=Mild) = P(Weather=Overcast, Temp=Mild | Play=No) P(Play=No) / P(Weather=Overcast, Temp=Mild)\r\n",
        "\r\n",
        "P(Weather=Overcast, Temp=Mild | Play=No) = P(Overcast|Yes) P(Mild|No)\r\n",
        "\r\n",
        "1. 사전 확률\r\n",
        "\r\n",
        "P(No) = 5/14 = 0.36\r\n",
        "\r\n",
        "2. 사후 확률\r\n",
        "\r\n",
        "P(Overcast|No) = 0/5 = 0\r\n",
        "\r\n",
        "P(Mild|No) = 2/5 = 0.4\r\n",
        "\r\n",
        "3. 베이즈 공식에 대입\r\n",
        "\r\n",
        "P(Weather=Overcast, Temp=Mild | Play=No) = P(Overcast|No) P(Mild|No) = 0 * 0.4 = 0\r\n",
        "\r\n",
        "P(Paly=No | Weather=Overcast, Temp=Mild) = P(Weather=Overcast, Temp=Mild | Play=No) P(Play=No) / P(Weather=Overcast, Temp=Mild)\r\n",
        "\r\n",
        "= 0 * 0.36 / 0.1224 = 0\r\n",
        "\r\n",
        "축구를 할 확률은 1이고, 축구를 하지 않을 확률은 0입니다. 축구를 할 확률이 더 크기 때문에 날씨가 Overcast이고 기온이 Mild일 때는 축구를 할 것이라고 분류합니다. 이렇듯 나이브 베이즈는 베이즈 정리를 활용하여 확률이 더 큰 Label로 분류를 합니다. \r\n",
        "\r\n",
        "Scikit-learn을 활용한 나이브 베이즈 분류기 구축\r\n",
        "날씨, 기온에 따른 축구 여부 분류\r\n",
        "2개의 Feature (Weather, Temp)와 1개의 Label (Play)로 구성된 dataset을 아래와 같이 만들어 주었습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kjzYwN-oPyx"
      },
      "source": [
        "weather = ['Sunny','Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',\r\n",
        "'Rainy','Sunny','Overcast','Overcast','Rainy']\r\n",
        "temp = ['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\r\n",
        "play = ['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuEdjw5Dol-Q",
        "outputId": "7d2e39d7-088c-49c7-b3cc-b2bf34067aa9"
      },
      "source": [
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "#Import and create LabelEncoder\r\n",
        "le = preprocessing.LabelEncoder()\r\n",
        "\r\n",
        "#Converting string Labels into numbers\r\n",
        "weather_encoded = le.fit_transform(weather)\r\n",
        "print(weather_encoded)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I34SnxFno4LX",
        "outputId": "91200eeb-36bf-4422-bfa5-c90d3bd26541"
      },
      "source": [
        "temp_encoded = le.fit_transform(temp)\r\n",
        "label = le.fit_transform(play)\r\n",
        "print(\"Temp:\", temp_encoded)\r\n",
        "print(\"Play:\", label)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temp: [1 1 1 2 0 0 0 2 0 2 2 2 1 2]\n",
            "Play: [0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R796PgjLpaQa",
        "outputId": "90cf7131-927e-4536-865b-4c563f8ee4eb"
      },
      "source": [
        "#Combining weather and temp intp single list of tuples\r\n",
        "\r\n",
        "features = zip(weather_encoded, temp_encoded)\r\n",
        "features = list(features)\r\n",
        "print(features)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(2, 1), (2, 1), (2, 1), (0, 2), (1, 0), (1, 0), (1, 0), (0, 2), (2, 0), (2, 2), (1, 2), (2, 2), (0, 1), (0, 2)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REe4Qh8fporr",
        "outputId": "0708bc59-f1f0-4ea8-8dc6-073f984f12c9"
      },
      "source": [
        "#Import Gaussian Naive Bayes model\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "\r\n",
        "#create a gaussian classifier\r\n",
        "model = GaussianNB()\r\n",
        "\r\n",
        "#Train the model using the training sets\r\n",
        "model.fit(features, label)\r\n",
        "\r\n",
        "#Predict output\r\n",
        "predicted = model.predict([[0, 2]]) #0:Overcast, 2: Mild\r\n",
        "print(\"Predicted Value:\", predicted) #1: Yes"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Value: [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcH_6zWdqaA4",
        "outputId": "572dd4d9-e5cd-4e87-d5ce-85da4e6ae871"
      },
      "source": [
        "#Import scikit-learn dataset library\r\n",
        "from sklearn import datasets\r\n",
        "\r\n",
        "#Load dataset\r\n",
        "wine = datasets.load_wine()\r\n",
        "\r\n",
        "#print the names of the 13 features\r\n",
        "print(\"Features: \", wine.feature_names)\r\n",
        "\r\n",
        "#print the label type of wine(class_0, class_1, class_2)\r\n",
        "print(\"Labels: \", wine.target_names)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
            "Labels:  ['class_0' 'class_1' 'class_2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZW80LKAq22D",
        "outputId": "6bd0adc3-b89e-49c3-c944-6825d371689e"
      },
      "source": [
        "wine.data.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk-NEdEPq7rX",
        "outputId": "22b73aef-f607-4db0-9707-4c0dc96d0ad6"
      },
      "source": [
        "wine.data[0:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.423e+01, 1.710e+00, 2.430e+00, 1.560e+01, 1.270e+02, 2.800e+00,\n",
              "        3.060e+00, 2.800e-01, 2.290e+00, 5.640e+00, 1.040e+00, 3.920e+00,\n",
              "        1.065e+03],\n",
              "       [1.320e+01, 1.780e+00, 2.140e+00, 1.120e+01, 1.000e+02, 2.650e+00,\n",
              "        2.760e+00, 2.600e-01, 1.280e+00, 4.380e+00, 1.050e+00, 3.400e+00,\n",
              "        1.050e+03],\n",
              "       [1.316e+01, 2.360e+00, 2.670e+00, 1.860e+01, 1.010e+02, 2.800e+00,\n",
              "        3.240e+00, 3.000e-01, 2.810e+00, 5.680e+00, 1.030e+00, 3.170e+00,\n",
              "        1.185e+03],\n",
              "       [1.437e+01, 1.950e+00, 2.500e+00, 1.680e+01, 1.130e+02, 3.850e+00,\n",
              "        3.490e+00, 2.400e-01, 2.180e+00, 7.800e+00, 8.600e-01, 3.450e+00,\n",
              "        1.480e+03],\n",
              "       [1.324e+01, 2.590e+00, 2.870e+00, 2.100e+01, 1.180e+02, 2.800e+00,\n",
              "        2.690e+00, 3.900e-01, 1.820e+00, 4.320e+00, 1.040e+00, 2.930e+00,\n",
              "        7.350e+02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cG7g6p1q-n3",
        "outputId": "34e78449-eb2a-4efd-f84c-4f34bff3d118"
      },
      "source": [
        "wine.target\r\n",
        "# class_0: 0, class_1: 1, class_2: 2"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSDg_CGjrJpS",
        "outputId": "a34d6b3a-634c-49d8-eed2-10fabf5516b3"
      },
      "source": [
        "#As we need to divide the sets into training set and test set\r\n",
        "\r\n",
        "#import train_test_split function\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "#split dataset into training set and test set\r\n",
        "#70% training and 30% test\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size = 0.3, random_state = 109)\r\n",
        "\r\n",
        "#Import Gaussian Naive Bayes model\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "\r\n",
        "#Create a Gaussian Classifier\r\n",
        "gnb = GaussianNB()\r\n",
        "\r\n",
        "#Train the model using the training sets\r\n",
        "gnb.fit(X_train, y_train)\r\n",
        "\r\n",
        "#Predict the response for test dataset\r\n",
        "y_pred = gnb.predict(X_test)\r\n",
        "\r\n",
        "#import scikit-learn metrics module for accuracy calculation\r\n",
        "from sklearn import metrics\r\n",
        "\r\n",
        "#Model Accuracy, how often is the classifier correct?\r\n",
        "\r\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9074074074074074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxVHoGs9ucPY"
      },
      "source": [
        "1. random_state=109 : 109로 하신 이유가 있는지요?\r\n",
        "2. 수동으로 아래와 같이 입력을 해보았습니다.\r\n",
        "aaa = gnb.predict([[1,1,1,1,1,1,1,1,1,1,1,1,1]])\r\n",
        "print(aaa)\r\n",
        ">[ 1]\r\n",
        "여기서 1이 'class_1' 을 의미하는 것이 맞는지요?\r\n",
        "맞다면 1 대신에 'class_1' 이라고 보여지려면 어떻게 해야 될지요?\r\n",
        "\r\n",
        "\r\n",
        "1. 이유는 없습니다. random_state는 임의의 숫자를 넣어서 시드를 고정해주는 것입니다. 그냥 좋아하는 숫자를 넣으시면 됩니다. 그러나 다른 많은 코드를 보면 42가 종종 등장합니다. 이유는 모르겠으나 관습 같습니다 ㅎㅎ\r\n",
        "\r\n",
        "2. 네, 1이 class_1을 뜻하는 것 맞습니다. 1대신 class_1으로 보여지려면 dict 등의 자료형을 활용하여 결과값 자체를 변환해야 합니다.\r\n",
        "머신러닝 모델은 숫자를 입력받아 숫자를 출력합니다. 문자를 입력받아 문자를 출력하는 것처럼 보이는 이유는 입력단에서 문자를 숫자로 바꾸어주고 (이를 임베딩이라 합니다.) 출력단에서 숫자를 문자로 바꾸어주기 때문입니다.\r\n",
        "따라서 모델 자체가 predict했을 때 문자를 출력하게 하는 기능은 제가 아는 한 없습니다. (있는데 제가 모르는 것일수도 있습니다 ㅎㅎ)\r\n",
        "\r\n",
        "결국 출력한 숫자 1을 class_1로 그냥 변환해주어야 합니다 ^^"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu53WT8utCO0"
      },
      "source": [
        "나이브 베이즈의 장단점\r\n",
        "장점\r\n",
        "\r\n",
        "1. 간단하고, 빠르며, 정확한 모델입니다.\r\n",
        "\r\n",
        "2. computation cost가 작습니다. (따라서 빠릅니다.)\r\n",
        "\r\n",
        "3. 큰 데이터셋에 적합합니다.\r\n",
        "\r\n",
        "4. 연속형보다 이산형 데이터에서 성능이 좋습니다.\r\n",
        "\r\n",
        "5. Multiple class 예측을 위해서도 사용할 수 있습니다.\r\n",
        "\r\n",
        "단점\r\n",
        "\r\n",
        "feature 간의 독립성이 있어야 합니다. 하지만 실제 데이터에서 모든 feature가 독립인 경우는 드뭅니다. 장점이 많지만 feature가 서로 독립이어야 한다는 크리티컬한 단점이 있습니다.\r\n",
        "\r\n",
        "feature간 독립성이 있다는 말은 feature간에 서로 상관관계가 없다는 뜻입니다. X1과 X2라는 feature가 있을 때 X1이 증가하면 X2도 같이 증가한다고 합시다. 그럼 X1과 X2는 서로 상관관계가 있다고 말할 수 있고, 이는 X1과 X2가 독립성이 없다는 뜻입니다. X1과 X2가 독립성이 있으려면 X1이 증가하든 말든, X2에는 아무런 영향을 미치지 않아야 합니다. 하지만 우리가 얻을 수 있는 데이터에서는 feature간의 독립성이 항상 보장되지는 않습니다. 나이브 베이즈 모델은 feature간 독립성이 있다는 가정하에 성립되는 모델이기 때문에 실생활에서 바로 적용하기는 어려움있습니다."
      ]
    }
  ]
}